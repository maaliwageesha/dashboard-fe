{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8069736-2175-4498-b0f6-1620cdeefafc",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading documents for AUS from C:\\Users\\u\\OneDrive - Swinburne University\\Policy Documents\\Policy docs-AUS\n",
      "Loaded 18 documents for AUS\n",
      "\n",
      "Loading documents for CHN from C:\\Users\\u\\OneDrive - Swinburne University\\Policy Documents\\Policy docs-China\n",
      "Loaded 20 documents for CHN\n",
      "\n",
      "Loading documents for IND from C:\\Users\\u\\OneDrive - Swinburne University\\Policy Documents\\Policy docs-Ind\n",
      "Loaded 15 documents for IND\n",
      "\n",
      "Loading documents for SING from C:\\Users\\u\\OneDrive - Swinburne University\\Policy Documents\\Policy docs-Sing\n",
      "Loaded 8 documents for SING\n",
      "\n",
      "Total countries loaded: 4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pdfplumber\n",
    "import docx\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = ''\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() or ''\n",
    "    return text\n",
    "\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    doc = docx.Document(docx_path)\n",
    "    return \" \".join([para.text for para in doc.paragraphs])\n",
    "\n",
    "\n",
    "def load_documents(directory):\n",
    "    docs = []\n",
    "    files_in_directory = os.listdir(directory)\n",
    "    \n",
    "    for filename in files_in_directory:\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        if filename.endswith('.pdf'):\n",
    "            text = extract_text_from_pdf(file_path)\n",
    "            if text:\n",
    "                docs.append(text)\n",
    "        elif filename.endswith('.docx'):\n",
    "            text = extract_text_from_docx(file_path)\n",
    "            if text:\n",
    "                docs.append(text)\n",
    "    return docs\n",
    "\n",
    "\n",
    "directories = {\n",
    "    'AUS': r\"C:\\Users\\u\\OneDrive - Swinburne University\\Policy Documents\\Policy docs-AUS\",\n",
    "    'CHN': r\"C:\\Users\\u\\OneDrive - Swinburne University\\Policy Documents\\Policy docs-China\",\n",
    "    'IND': r\"C:\\Users\\u\\OneDrive - Swinburne University\\Policy Documents\\Policy docs-Ind\",\n",
    "    'SING': r\"C:\\Users\\u\\OneDrive - Swinburne University\\Policy Documents\\Policy docs-Sing\"\n",
    "}\n",
    "\n",
    "\n",
    "country_docs = {}\n",
    "\n",
    "\n",
    "for country, directory in directories.items():\n",
    "    print(f\"Loading documents for {country} from {directory}\")\n",
    "    docs = load_documents(directory)  \n",
    "    if docs:\n",
    "        country_docs[country] = docs  \n",
    "        print(f\"Loaded {len(docs)} documents for {country}\\n\")\n",
    "    else:\n",
    "        print(f\"No documents loaded for {country}\\n\")\n",
    "\n",
    "\n",
    "print(f\"Total countries loaded: {len(country_docs)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebc84303-cc7f-41c4-b736-21729d5075e6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning documents for AUS...\n",
      "Finished cleaning 18 documents for AUS\n",
      "\n",
      "Cleaning documents for CHN...\n",
      "Finished cleaning 20 documents for CHN\n",
      "\n",
      "Cleaning documents for IND...\n",
      "Finished cleaning 15 documents for IND\n",
      "\n",
      "Cleaning documents for SING...\n",
      "Finished cleaning 8 documents for SING\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import spacy\n",
    "\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "   \n",
    "    lower_text = re.sub(r'\\d+', '', text.lower())  \n",
    "    doc = nlp(lower_text)\n",
    "    tokens = [token.lemma_ for token in doc if token.is_alpha and not token.is_stop]  \n",
    "    clean_text = \" \".join(tokens)\n",
    "    clean_text = re.sub(r'\\s+', ' ', clean_text).strip()  \n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def clean_country_documents(country_docs):\n",
    "    cleaned_docs_by_country = {}  \n",
    "    \n",
    "    for country, docs in country_docs.items():\n",
    "        print(f\"Cleaning documents for {country}...\")\n",
    "        cleaned_docs = [preprocess_text(doc) for doc in docs]  \n",
    "        cleaned_docs_by_country[country] = cleaned_docs\n",
    "        print(f\"Finished cleaning {len(docs)} documents for {country}\\n\")\n",
    "    \n",
    "    return cleaned_docs_by_country\n",
    "\n",
    "\n",
    "cleaned_docs_by_country = clean_country_documents(country_docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d2de438-68d4-45bd-ab7c-acc1da3fd882",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0: 0.031*\"wind\" + 0.016*\"farm\" + 0.012*\"committee\" + 0.011*\"energy\" + 0.010*\"mr\" + 0.009*\"turbine\" + 0.008*\"health\" + 0.008*\"submission\" + 0.007*\"state\" + 0.006*\"noise\"\n",
      "Topic 1: 0.027*\"licence\" + 0.023*\"subclause\" + 0.017*\"provide\" + 0.016*\"clause\" + 0.014*\"offshore\" + 0.013*\"person\" + 0.011*\"infrastructure\" + 0.011*\"provision\" + 0.010*\"area\" + 0.010*\"bill\"\n",
      "Topic 2: 0.017*\"solar\" + 0.014*\"power\" + 0.009*\"plant\" + 0.009*\"project\" + 0.009*\"date\" + 0.007*\"consumer\" + 0.007*\"electricity\" + 0.006*\"state\" + 0.006*\"rs\" + 0.006*\"include\"\n",
      "Topic 3: 0.020*\"energy\" + 0.015*\"cefc\" + 0.015*\"project\" + 0.010*\"grant\" + 0.009*\"investment\" + 0.009*\"bill\" + 0.009*\"clean\" + 0.008*\"fund\" + 0.007*\"technology\" + 0.007*\"grid\"\n",
      "Topic 4: 0.018*\"australia\" + 0.017*\"energy\" + 0.016*\"emission\" + 0.013*\"technology\" + 0.010*\"hydrogen\" + 0.008*\"low\" + 0.007*\"carbon\" + 0.007*\"project\" + 0.007*\"government\" + 0.006*\"australian\"\n",
      "LDA visualization saved as 'combined_lda.html'\n"
     ]
    }
   ],
   "source": [
    "import pyLDAvis\n",
    "import pyLDAvis.gensim as gensimvis\n",
    "from gensim import corpora, models\n",
    "\n",
    "\n",
    "tokenized_docs = [doc.split() for doc in combined_cleaned_docs]\n",
    "dictionary = corpora.Dictionary(tokenized_docs)\n",
    "corpus = [dictionary.doc2bow(doc) for doc in tokenized_docs]\n",
    "lda_model = models.LdaModel(corpus, num_topics=5, id2word=dictionary, passes=10, random_state=100)\n",
    "topics = lda_model.print_topics(num_words=10)\n",
    "for idx, topic in topics:\n",
    "    print(f\"Topic {idx}: {topic}\")\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "vis_data = gensimvis.prepare(lda_model, corpus, dictionary)\n",
    "\n",
    "pyLDAvis.display(vis_data)\n",
    "\n",
    "pyLDAvis.save_html(vis_data, 'combined_lda.html')\n",
    "print(\"LDA visualization saved as 'combined_lda.html'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3f82d344-fc6a-48dd-bdbc-5a1df7d08fb0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "all_text = ' '.join(combined_cleaned_docs)\n",
    "\n",
    "word_counts = Counter(all_text.split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c0b3a33b-d899-43b5-a12c-d0df9bc34144",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word cloud saved as 'combined_wordcloud.html'.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import plotly.graph_objs as go\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "all_text = ' '.join(combined_cleaned_docs)  \n",
    "word_counts = Counter(all_text.split())\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=200).generate_from_frequencies(word_counts)\n",
    "wordcloud_image = wordcloud.to_image()\n",
    "wordcloud_array = np.array(wordcloud_image)\n",
    "trace = go.Image(z=wordcloud_array)\n",
    "\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis=dict(showgrid=False, showticklabels=False, zeroline=False),\n",
    "    yaxis=dict(showgrid=False, showticklabels=False, zeroline=False),\n",
    "    margin=dict(l=0, r=0, b=0, t=0)\n",
    ")\n",
    "\n",
    "\n",
    "fig = go.Figure(data=[trace], layout=layout)\n",
    "fig.write_html('combined_wordcloud.html')\n",
    "\n",
    "print(\"Word cloud saved as 'combined_wordcloud.html'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1265382-08cf-418b-9be6-9ada16d021ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
