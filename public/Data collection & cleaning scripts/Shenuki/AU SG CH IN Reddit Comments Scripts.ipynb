{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c906b11-4923-4c26-a847-2f0405ab7563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "\n",
    "# Set up Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id='25Yjnzk9vYkRVFUQnfMZgg',\n",
    "    client_secret='FXBbwO4igyzsY8bSoXt0AR8IEnjGFg',\n",
    "    user_agent='windows:reddit_scraper:1.0 (by /u/Infinite-Respond-832 )'\n",
    ")\n",
    "\n",
    "# Define the subreddits and search query\n",
    "subreddits = ['singapore','renewableenergy', 'environment' , 'energy']\n",
    "search_query = 'renewable energy singapore'\n",
    "\n",
    "# Function to scrape Reddit posts and their comments\n",
    "def scrape_reddit_posts(subreddits, search_query, limit=100):\n",
    "    posts_data = []\n",
    "    \n",
    "    for subreddit_name in subreddits:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "        # Search for posts\n",
    "        for submission in subreddit.search(search_query, limit=limit):\n",
    "            post_info = {\n",
    "                'Title': submission.title,\n",
    "                'Subreddit': subreddit_name,\n",
    "                'Author': str(submission.author),\n",
    "                'URL': submission.url,\n",
    "                'Created (UTC)': submission.created_utc,\n",
    "                'Score': submission.score,\n",
    "                'Number of Comments': submission.num_comments,\n",
    "                'Content': submission.selftext,  # Post content\n",
    "            }\n",
    "            posts_data.append(post_info)\n",
    "            \n",
    "            # Fetch comments for the post\n",
    "            submission.comments.replace_more(limit=5)  # Load all comments\n",
    "            for comment in submission.comments.list():\n",
    "                comment_info = {\n",
    "                    'Post Title': submission.title,\n",
    "                    'Subreddit': subreddit_name,\n",
    "                    'Comment Author': str(comment.author),\n",
    "                    'Comment': comment.body,\n",
    "                    'Comment Created (UTC)': comment.created_utc,\n",
    "                    'Comment Score': comment.score\n",
    "                }\n",
    "                posts_data.append(comment_info)  # Append comment data\n",
    "    \n",
    "    return posts_data\n",
    "\n",
    "# Run the scraping function\n",
    "posts = scrape_reddit_posts(subreddits, search_query)\n",
    "\n",
    "# Convert the scraped data to a DataFrame\n",
    "df = pd.DataFrame(posts)\n",
    "# Replace NaN or non-string values with an empty string\n",
    "df['Content'] = df['Content'].fillna('')\n",
    "\n",
    "# Function to perform sentiment analysis using TextBlob\n",
    "def analyze_sentiment(content):\n",
    "    analysis = TextBlob(content)\n",
    "    return analysis.sentiment.polarity  # Polarity ranges from -1 (negative) to 1 (positive)\n",
    "\n",
    "# Apply sentiment analysis to each post's content\n",
    "df['Sentiment'] = df['Content'].apply(analyze_sentiment)\n",
    "\n",
    "# Categorize sentiment as positive, negative, or neutral\n",
    "def categorize_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['Sentiment Category'] = df['Sentiment'].apply(categorize_sentiment)\n",
    "\n",
    "# Function to remove illegal characters\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove any illegal characters that Excel does not accept\n",
    "        return re.sub(r'[\\x00-\\x1F\\x7F]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to all string columns in the DataFrame\n",
    "df_clean = df.applymap(clean_text)\n",
    "\n",
    "# Save the cleaned DataFrame to an Excel file\n",
    "output_file = 'Reddit_SG_SA_cleaned.xlsx'\n",
    "df_clean.to_excel(output_file, index=False)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edeed49d-cdac-4a9b-aa86-5652efdd6c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id='25Yjnzk9vYkRVFUQnfMZgg',\n",
    "    client_secret='FXBbwO4igyzsY8bSoXt0AR8IEnjGFg',\n",
    "    user_agent='windows:reddit_scraper:1.0 (by /u/Infinite-Respond-832 )'\n",
    ")\n",
    "\n",
    "# Define the subreddits and search query\n",
    "subreddits = ['australia','renewableenergy', 'environment' , 'energy']\n",
    "search_query = 'renewable energy australia'\n",
    "\n",
    "# Function to scrape Reddit posts and their comments\n",
    "def scrape_reddit_posts(subreddits, search_query, limit=100):\n",
    "    posts_data = []\n",
    "    \n",
    "    for subreddit_name in subreddits:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "        # Search for posts\n",
    "        for submission in subreddit.search(search_query, limit=limit):\n",
    "            post_info = {\n",
    "                'Title': submission.title,\n",
    "                'Subreddit': subreddit_name,\n",
    "                'Author': str(submission.author),\n",
    "                'URL': submission.url,\n",
    "                'Created (UTC)': submission.created_utc,\n",
    "                'Score': submission.score,\n",
    "                'Number of Comments': submission.num_comments,\n",
    "                'Content': submission.selftext,  # Post content\n",
    "            }\n",
    "            posts_data.append(post_info)\n",
    "            \n",
    "            # Fetch comments for the post\n",
    "            submission.comments.replace_more(limit=5)  # Load all comments\n",
    "            for comment in submission.comments.list():\n",
    "                comment_info = {\n",
    "                    'Post Title': submission.title,\n",
    "                    'Subreddit': subreddit_name,\n",
    "                    'Comment Author': str(comment.author),\n",
    "                    'Comment': comment.body,\n",
    "                    'Comment Created (UTC)': comment.created_utc,\n",
    "                    'Comment Score': comment.score\n",
    "                }\n",
    "                posts_data.append(comment_info)  # Append comment data\n",
    "    \n",
    "    return posts_data\n",
    "\n",
    "# Run the scraping function\n",
    "posts = scrape_reddit_posts(subreddits, search_query)\n",
    "\n",
    "# Convert the scraped data to a DataFrame\n",
    "df = pd.DataFrame(posts)\n",
    "# Replace NaN or non-string values with an empty string\n",
    "df['Content'] = df['Content'].fillna('')\n",
    "\n",
    "# Function to perform sentiment analysis using TextBlob\n",
    "def analyze_sentiment(content):\n",
    "    analysis = TextBlob(content)\n",
    "    return analysis.sentiment.polarity  # Polarity ranges from -1 (negative) to 1 (positive)\n",
    "\n",
    "# Apply sentiment analysis to each post's content\n",
    "df['Sentiment'] = df['Content'].apply(analyze_sentiment)\n",
    "\n",
    "# Categorize sentiment as positive, negative, or neutral\n",
    "def categorize_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['Sentiment Category'] = df['Sentiment'].apply(categorize_sentiment)\n",
    "\n",
    "# Function to remove illegal characters\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove any illegal characters that Excel does not accept\n",
    "        return re.sub(r'[\\x00-\\x1F\\x7F]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to all string columns in the DataFrame\n",
    "df_clean = df.applymap(clean_text)\n",
    "\n",
    "# Save the cleaned DataFrame to an Excel file\n",
    "output_file = 'Reddit_AU_SA_cleaned.xlsx'\n",
    "df_clean.to_excel(output_file, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efb78ada-9025-4514-9ec6-76441a07d5b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id='25Yjnzk9vYkRVFUQnfMZgg',\n",
    "    client_secret='FXBbwO4igyzsY8bSoXt0AR8IEnjGFg',\n",
    "    user_agent='windows:reddit_scraper:1.0 (by /u/Infinite-Respond-832 )'\n",
    ")\n",
    "\n",
    "# Define the subreddits and search query\n",
    "subreddits = ['china','renewableenergy', 'environment' , 'energy']\n",
    "search_query = 'renewable energy China'\n",
    "\n",
    "# Function to scrape Reddit posts and their comments\n",
    "def scrape_reddit_posts(subreddits, search_query, limit=100):\n",
    "    posts_data = []\n",
    "    \n",
    "    for subreddit_name in subreddits:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "        # Search for posts\n",
    "        for submission in subreddit.search(search_query, limit=limit):\n",
    "            post_info = {\n",
    "                'Title': submission.title,\n",
    "                'Subreddit': subreddit_name,\n",
    "                'Author': str(submission.author),\n",
    "                'URL': submission.url,\n",
    "                'Created (UTC)': submission.created_utc,\n",
    "                'Score': submission.score,\n",
    "                'Number of Comments': submission.num_comments,\n",
    "                'Content': submission.selftext,  # Post content\n",
    "            }\n",
    "            posts_data.append(post_info)\n",
    "            \n",
    "            # Fetch comments for the post\n",
    "            submission.comments.replace_more(limit=5)  # Load all comments\n",
    "            for comment in submission.comments.list():\n",
    "                comment_info = {\n",
    "                    'Post Title': submission.title,\n",
    "                    'Subreddit': subreddit_name,\n",
    "                    'Comment Author': str(comment.author),\n",
    "                    'Comment': comment.body,\n",
    "                    'Comment Created (UTC)': comment.created_utc,\n",
    "                    'Comment Score': comment.score\n",
    "                }\n",
    "                posts_data.append(comment_info)  # Append comment data\n",
    "    \n",
    "    return posts_data\n",
    "\n",
    "# Run the scraping function\n",
    "posts = scrape_reddit_posts(subreddits, search_query)\n",
    "\n",
    "# Convert the scraped data to a DataFrame\n",
    "df = pd.DataFrame(posts)\n",
    "# Replace NaN or non-string values with an empty string\n",
    "df['Content'] = df['Content'].fillna('')\n",
    "\n",
    "# Function to perform sentiment analysis using TextBlob\n",
    "def analyze_sentiment(content):\n",
    "    analysis = TextBlob(content)\n",
    "    return analysis.sentiment.polarity  # Polarity ranges from -1 (negative) to 1 (positive)\n",
    "\n",
    "# Apply sentiment analysis to each post's content\n",
    "df['Sentiment'] = df['Content'].apply(analyze_sentiment)\n",
    "\n",
    "# Categorize sentiment as positive, negative, or neutral\n",
    "def categorize_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['Sentiment Category'] = df['Sentiment'].apply(categorize_sentiment)\n",
    "\n",
    "# Function to remove illegal characters\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove any illegal characters that Excel does not accept\n",
    "        return re.sub(r'[\\x00-\\x1F\\x7F]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to all string columns in the DataFrame\n",
    "df_clean = df.applymap(clean_text)\n",
    "\n",
    "# Save the cleaned DataFrame to an Excel file\n",
    "output_file = 'Reddit_CH_SA_cleaned.xlsx'\n",
    "df_clean.to_excel(output_file, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c0250f0-7884-41c5-acc5-44c1ccb783a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import praw\n",
    "import pandas as pd\n",
    "from textblob import TextBlob\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Set up Reddit API credentials\n",
    "reddit = praw.Reddit(\n",
    "    client_id='25Yjnzk9vYkRVFUQnfMZgg',\n",
    "    client_secret='FXBbwO4igyzsY8bSoXt0AR8IEnjGFg',\n",
    "    user_agent='windows:reddit_scraper:1.0 (by /u/Infinite-Respond-832 )'\n",
    ")\n",
    "\n",
    "# Define the subreddits and search query\n",
    "subreddits = ['india','renewableenergy', 'environment' , 'energy']\n",
    "search_query = 'renewable energy India'\n",
    "\n",
    "# Function to scrape Reddit posts and their comments\n",
    "def scrape_reddit_posts(subreddits, search_query, limit=100):\n",
    "    posts_data = []\n",
    "    \n",
    "    for subreddit_name in subreddits:\n",
    "        subreddit = reddit.subreddit(subreddit_name)\n",
    "\n",
    "        # Search for posts\n",
    "        for submission in subreddit.search(search_query, limit=limit):\n",
    "            post_info = {\n",
    "                'Title': submission.title,\n",
    "                'Subreddit': subreddit_name,\n",
    "                'Author': str(submission.author),\n",
    "                'URL': submission.url,\n",
    "                'Created (UTC)': submission.created_utc,\n",
    "                'Score': submission.score,\n",
    "                'Number of Comments': submission.num_comments,\n",
    "                'Content': submission.selftext,  # Post content\n",
    "            }\n",
    "            posts_data.append(post_info)\n",
    "            \n",
    "            # Fetch comments for the post\n",
    "            submission.comments.replace_more(limit=5)  # Load all comments\n",
    "            for comment in submission.comments.list():\n",
    "                comment_info = {\n",
    "                    'Post Title': submission.title,\n",
    "                    'Subreddit': subreddit_name,\n",
    "                    'Comment Author': str(comment.author),\n",
    "                    'Comment': comment.body,\n",
    "                    'Comment Created (UTC)': comment.created_utc,\n",
    "                    'Comment Score': comment.score\n",
    "                }\n",
    "                posts_data.append(comment_info)  # Append comment data\n",
    "    \n",
    "    return posts_data\n",
    "\n",
    "# Run the scraping function\n",
    "posts = scrape_reddit_posts(subreddits, search_query)\n",
    "\n",
    "# Convert the scraped data to a DataFrame\n",
    "df = pd.DataFrame(posts)\n",
    "# Replace NaN or non-string values with an empty string\n",
    "df['Content'] = df['Content'].fillna('')\n",
    "\n",
    "# Function to perform sentiment analysis using TextBlob\n",
    "def analyze_sentiment(content):\n",
    "    analysis = TextBlob(content)\n",
    "    return analysis.sentiment.polarity  # Polarity ranges from -1 (negative) to 1 (positive)\n",
    "\n",
    "# Apply sentiment analysis to each post's content\n",
    "df['Sentiment'] = df['Content'].apply(analyze_sentiment)\n",
    "\n",
    "# Categorize sentiment as positive, negative, or neutral\n",
    "def categorize_sentiment(polarity):\n",
    "    if polarity > 0:\n",
    "        return 'Positive'\n",
    "    elif polarity < 0:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Neutral'\n",
    "\n",
    "df['Sentiment Category'] = df['Sentiment'].apply(categorize_sentiment)\n",
    "\n",
    "# Function to remove illegal characters\n",
    "def clean_text(text):\n",
    "    if isinstance(text, str):\n",
    "        # Remove any illegal characters that Excel does not accept\n",
    "        return re.sub(r'[\\x00-\\x1F\\x7F]', '', text)\n",
    "    return text\n",
    "\n",
    "# Apply the cleaning function to all string columns in the DataFrame\n",
    "df_clean = df.applymap(clean_text)\n",
    "\n",
    "# Save the cleaned DataFrame to an Excel file\n",
    "output_file = 'Reddit_IN_SA_cleaned.xlsx'\n",
    "df_clean.to_excel(output_file, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b5d709-4673-4c41-8e8d-888aa710d57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
